{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerospace-engineering\n",
      "agricultural-engineering\n",
      "architectural-engineering\n",
      "biomedical-engineering\n",
      "chemical-engineering\n",
      "civil-engineering\n",
      "computer-engineering\n",
      "construction-engineering\n",
      "electrical-engineering\n",
      "environmental-engineering\n",
      "financial-engineering\n",
      "geotechnical-engineering\n",
      "industrial-engineering\n",
      "manufacturing-engineering\n",
      "marine-engineering\n",
      "materials-engineering\n",
      "mechanical-engineering\n",
      "metallurgical-engineering\n",
      "mining-engineering\n",
      "network-engineering\n",
      "nuclear-engineering\n",
      "packaging-engineering\n",
      "petroleum-engineering\n",
      "process-engineering\n",
      "project-engineering\n",
      "quality-engineering\n",
      "safety-engineering\n",
      "sales-engineering\n",
      "software-engineering\n",
      "solar-engineering\n",
      "structural-engineering\n",
      "systems-engineering\n",
      "Completed in 0:01:11.456000\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import common\n",
    "import datetime as dt\n",
    "fields = common.fields\n",
    "engine = common.engine\n",
    "import re\n",
    "startTime = dt.datetime.now()\n",
    "\n",
    "\n",
    "#DEBUG\n",
    "'''url = \"https://www.indeed.com/jobs?as_and=\"+fields[0]+\"&fromage=1&limit=50&sort=date\"\n",
    "jobs = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(jobs, 'html.parser')\n",
    "for link in soup('div', class_='  row  result'):\n",
    "    print link('h2', class_='jobtitle')[0].a.text, 'https://www.indeed.com' + link('h2', class_='jobtitle')[0].a['href'],\n",
    "    try:\n",
    "        print link('span', class_='company')[0].a.text.strip(), link('span', {'itemprop':'addressLocality'})[0].text.strip()\n",
    "    except AttributeError:\n",
    "        print link('span', class_='company')[0].text.strip(), link('span', {'itemprop':'addressLocality'})[0].text.strip()\n",
    "#DEBUG'''\n",
    "\n",
    "for field in fields: \n",
    "    url = \"https://www.indeed.com/jobs?as_and=\"+field+\"&fromage=1&limit=50&sort=date\"\n",
    "    sql = \"INSERT INTO `%s-jobs` VALUES\"%(field)\n",
    "    counter = 50\n",
    "    while True:\n",
    "        try:\n",
    "            jobs = urllib2.urlopen(url)\n",
    "        except urllib2.HTTPError:\n",
    "            print \"URL error: \", url\n",
    "            break\n",
    "        soup = BeautifulSoup(jobs, 'html.parser')\n",
    "        for link in soup('div', class_='  row  result'):\n",
    "            sql += '(\"%s\",\"%s\",' %(link('h2', class_='jobtitle')[0].a.text.replace('\"','\\\\\"'), 'https://www.indeed.com' + link('h2', class_='jobtitle')[0].a['href'])\n",
    "            try:\n",
    "                sql += '\"%s\",\"%s\",\"%s\"),'%(link('span', class_='company')[0].a.text.strip().replace('\"','\\\\\"'), link('span', {'itemprop':'addressLocality'})[0].text.strip().replace('\"','\\\\\"'),\\\n",
    "                                          re.sub(r'.*?, *', '', link('span', {'itemprop':'addressLocality'})[0].text.strip().replace('\"','\\\\\"')))\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    sql += '\"%s\",\"%s\",\"%s\"),'%(link('span', class_='company')[0].text.strip().replace('\"','\\\\\"'), link('span', {'itemprop':'addressLocality'})[0].text.strip().replace('\"','\\\\\"'),\\\n",
    "                                          re.sub(r'.*?, *', '', link('span', {'itemprop':'addressLocality'})[0].text.strip().replace('\"','\\\\\"')))\n",
    "                except:\n",
    "                    sql += '\"%s\",\"%s\",\"%s\"),'%('','','')\n",
    "            except IndexError:\n",
    "                print \"Index error\"\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print e.message\n",
    "                pass\n",
    "        if any('Next' in spans.text for spans in soup('span', class_='pn')):\n",
    "            url = \"https://www.indeed.com/jobs?as_and=\"+field+\"&fromage=1&limit=50&sort=date&start=\"+str(counter)\n",
    "            counter += 50\n",
    "        else: \n",
    "            break\n",
    "    if sql != \"INSERT INTO `%s-jobs` VALUES\"%(field):\n",
    "        try:\n",
    "            engine.execute(sqlalchemy.text(sql[:-1]))\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            pass\n",
    "        \n",
    "print \"Completed in \" + str(dt.datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
